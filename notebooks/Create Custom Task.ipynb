{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003b73a2",
   "metadata": {},
   "source": [
    "# Custom Tasks with Task-Aware MoE LoRA for Universal Information Extraction\n",
    "\n",
    "This notebook is an example of how to run Custom Tasks with our Task-Aware MoELoRA model for Universal Information Extraction.\n",
    "This notebook is an adaptation of the \"Custom Tasks with GoLLIE\" notebook from the GoLLIE model repository (https://github.com/hitz-zentroa/GoLLIE/blob/main/notebooks/Create%20Custom%20Task.ipynb).\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "- How to define the guidelines for a task.\n",
    "- How to load the Task-Aware MoE LoRA model.\n",
    "- How to generate model inputs.\n",
    "- How to parse the output.\n",
    "\n",
    "You can modify this notebook to run any task you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b015c64",
   "metadata": {},
   "source": [
    "### Import requeriments\n",
    "\n",
    "As a first step, it is necessary to install the requirements.\n",
    "Please, look at the README.md file in the repository (https://github.com/lubingzhiguo/TA-MoELoRA) for detailed instructions on how to install the requirements for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ed51491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../model_tamoelora/\") # Add the GoLLIE base directory to sys path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28ff498a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tamoelora_python/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import rich\n",
    "import logging\n",
    "from src.model.load_model import load_model\n",
    "import black\n",
    "import inspect\n",
    "from jinja2 import Template as jinja2Template\n",
    "import tempfile\n",
    "from src.tasks.utils_typing import AnnotationList\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "from typing import Dict, List, Type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004626bb",
   "metadata": {},
   "source": [
    "## Load the Task-Aware MoE LoRA model.\n",
    "\n",
    "As a first step, we shall upload our Task-Aware MoE LoRA model from HuggingFace.\n",
    "\n",
    "We provide a load_model function in the repository that can be used, which we shall use in this repository.\n",
    "\n",
    "We set the following parameters:\n",
    "- `inference=True`: we indicate that we want to apply our model (not train it).\n",
    "- `model_weights_name_or_path`: the base model (in our case, codellama/CodeLlama-7b-hf)\n",
    "- `use_lora`: True, as we need to apply the LoRA weights over CodeLlama-7b.\n",
    "- `lora_type`: `moelora`, indicating that we are going to use a mixture of experts.\n",
    "- `moe_type`: the router to use. In our case, `pt_task_aware` to indicate the Task-Aware router.\n",
    "- `lora_weights_name_or_path`: the HuggingFace ID, or the path to the LoRA weights. In this case, we are collecting it from HuggingFace.\n",
    "- `quantization`: None. If the model does not fit GPU memory, apply `quantization=4`\n",
    "- `use_flash_attention`: Indicate if we want to use Flash Attention (by default, you should use it).\n",
    "- `torch_dtype`: the type of float (here, we use floating point 16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb841c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading model model from codellama/CodeLlama-7b-hf\n",
      "INFO:root:We will load the model using the following device map: None and max_memory: None\n",
      "WARNING:root:Tokenizer does not have a pad token, we will use the unk token as pad token.\n",
      "INFO:root:Loading model with dtype: torch.bfloat16\n",
      "WARNING:root:Model codellama/CodeLlama-7b-hf is an decoder-only model. We will load it as a CausalLM model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Flash Attention installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Using Flash Attention for LLaMA model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Flash RoPE installed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 15.81it/s]\n",
      "INFO:root:Model dtype: torch.bfloat16\n",
      "INFO:root:Total model memory footprint: 13477.101762 MB\n",
      "INFO:root:Loading pretrained LORA weights from lbzg/TA-MoELoRA\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading task embedding model: Salesforce/codet5-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/tamoelora_python/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "INFO:root:\n",
      "LoRA config:\n",
      "{'default': MoELoraConfig(peft_type=<PeftType.MOELORA: 'MOELORA'>, auto_mapping=None, base_model_name_or_path='codellama/CodeLlama-7b-hf', revision=None, task_type='CAUSAL_LM', inference_mode=True, r=4, target_modules=['q_proj', 'o_proj', 'k_proj', 'up_proj', 'down_proj', 'gate_proj', 'v_proj'], lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', use_rslora=False, modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None, rank_pattern={}, alpha_pattern={}, megatron_config=None, megatron_core='megatron.core', loftq_config={}, use_dora=False, layer_replication=None, runtime_config=LoraRuntimeConfig(ephemeral_gpu_offload=False), lora_nums=8, moe_type='pt_task_aware', task_embedding_model='Salesforce/codet5-base', task_id_mapping_path=None, task_dim=768, turn_off_last_layer_expert=None)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load_model(inference=True,\n",
    "                              model_weights_name_or_path=\"codellama/CodeLlama-7b-hf\",\n",
    "                              use_lora=True,\n",
    "                              lora_type=\"moelora\",\n",
    "                              moe_type=\"pt_task_aware\",\n",
    "                              lora_weights_name_or_path=\"lbzg/TA-MoELoRA\",\n",
    "                              quantization=None,\n",
    "                              use_flash_attention=True,\n",
    "                              torch_dtype=\"bfloat16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a662bf3",
   "metadata": {},
   "source": [
    "## Define the guidelines\n",
    "\n",
    "First, we will define the labels and guidelines for the task. We will represent them as Python classes.\n",
    "\n",
    "The following guidelines have been defined for this example. They were not part of the pre-training dataset. Therefore, we will run Task-Aware MoELoRA in zero-shot settings using unseen labels.\n",
    "\n",
    "We will use the `Generic` class, which is a versatile class that allows for the implementation of any task you want. However, since the model has never seen the Generic label during training, we will rename it to Template, which is recognized by the model (as it was used in the Tacred dataset).\n",
    "\n",
    "We will define two classes: `Launcher` and `Mission`. Each class will have a definition and a set of slots that the model needs to fill. Each slot also requires a type definition and a short description, which can include examples. For instance, for the `Launcher` class, we define three slots:\n",
    "\n",
    "- The `mention`, which will be the name of the Launcher vehicle and should be a string.\n",
    "- The `space_company` that operated the vehicle, which will also be a string.\n",
    "- The `crew`, which is defined as a list of astronauts. Therefore, Task-Aware MoELoRA will fill this slot with a list of strings.\n",
    "\n",
    "It is possible to define your own guidelines to apply on this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd5d262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from src.tasks.utils_typing import dataclass\n",
    "from src.tasks.utils_typing import Generic as Template\n",
    "\n",
    "\"\"\"\n",
    "Entity definitions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Launcher(Template):\n",
    "    \"\"\"Refers to a vehicle designed primarily to transport payloads from the Earth's \n",
    "    surface to space. Launchers can carry various payloads, including satellites, \n",
    "    crewed spacecraft, and cargo, into various orbits or even beyond Earth's orbit. \n",
    "    They are usually multi-stage vehicles that use rocket engines for propulsion.\"\"\"\n",
    "\n",
    "    mention: str  \n",
    "    \"\"\"\n",
    "    The name of the launcher vehicle. \n",
    "    Such as: \"Sturn V\", \"Atlas V\", \"Soyuz\", \"Ariane 5\"\n",
    "    \"\"\"\n",
    "    space_company: str # The company that operates the launcher. Such as: \"Blue origin\", \"ESA\", \"Boeing\", \"ISRO\", \"Northrop Grumman\", \"Arianespace\"\n",
    "    crew: List[str] # Names of the crew members boarding the Launcher. Such as: \"Neil Armstrong\", \"Michael Collins\", \"Buzz Aldrin\"\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Mission(Template):\n",
    "    \"\"\"Any planned or accomplished journey beyond Earth's atmosphere with specific objectives, \n",
    "    either crewed or uncrewed. It includes missions to satellites, the International \n",
    "    Space Station (ISS), other celestial bodies, and deep space.\"\"\"\n",
    "    \n",
    "    mention: str\n",
    "    \"\"\"\n",
    "    The name of the mission. \n",
    "    Such as: \"Apollo 11\", \"Artemis\", \"Mercury\"\n",
    "    \"\"\"\n",
    "    date: str # The start date of the mission\n",
    "    departure: str # The place from which the vehicle will be launched. Such as: \"Florida\", \"Houston\", \"French Guiana\"\n",
    "    destination: str # The place or planet to which the launcher will be sent. Such as \"Moon\", \"low-orbit\", \"Saturn\"\n",
    "\n",
    "\n",
    "ENTITY_DEFINITIONS: List[Template] = [\n",
    "    Launcher,\n",
    "    Mission,\n",
    "]\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    cell_txt = In[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8ef55",
   "metadata": {},
   "source": [
    "### Print the guidelines to guidelines.py\n",
    "\n",
    "Due to IPython limitations, we must write the content of the previous cell to a file and then import the content from that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4736a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"guidelines.py\",\"w\",encoding=\"utf8\") as python_guidelines:\n",
    "    print(cell_txt,file=python_guidelines)\n",
    "\n",
    "from guidelines import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3db6f",
   "metadata": {},
   "source": [
    "We use inspect.getsource to get the guidelines as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89454475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@dataclass\\nclass Launcher(Template):\\n    \"\"\"Refers to a vehicle designed primarily to transport payloads from the Earth\\'s \\n    surface to space. Launchers can carry various payloads, including satellites, \\n    crewed spacecraft, and cargo, into various orbits or even beyond Earth\\'s orbit. \\n    They are usually multi-stage vehicles that use rocket engines for propulsion.\"\"\"\\n\\n    mention: str  \\n    \"\"\"\\n    The name of the launcher vehicle. \\n    Such as: \"Sturn V\", \"Atlas V\", \"Soyuz\", \"Ariane 5\"\\n    \"\"\"\\n    space_company: str # The company that operates the launcher. Such as: \"Blue origin\", \"ESA\", \"Boeing\", \"ISRO\", \"Northrop Grumman\", \"Arianespace\"\\n    crew: List[str] # Names of the crew members boarding the Launcher. Such as: \"Neil Armstrong\", \"Michael Collins\", \"Buzz Aldrin\"\\n',\n",
       " '@dataclass\\nclass Mission(Template):\\n    \"\"\"Any planned or accomplished journey beyond Earth\\'s atmosphere with specific objectives, \\n    either crewed or uncrewed. It includes missions to satellites, the International \\n    Space Station (ISS), other celestial bodies, and deep space.\"\"\"\\n    \\n    mention: str\\n    \"\"\"\\n    The name of the mission. \\n    Such as: \"Apollo 11\", \"Artemis\", \"Mercury\"\\n    \"\"\"\\n    date: str # The start date of the mission\\n    departure: str # The place from which the vehicle will be launched. Such as: \"Florida\", \"Houston\", \"French Guiana\"\\n    destination: str # The place or planet to which the launcher will be sent. Such as \"Moon\", \"low-orbit\", \"Saturn\"\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guidelines = [inspect.getsource(definition) for definition in ENTITY_DEFINITIONS]\n",
    "guidelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bd26b7",
   "metadata": {},
   "source": [
    "## Define input sentence\n",
    "\n",
    "Here we define the input sentence and the gold labels.\n",
    "\n",
    "You can define and empy list as gold labels if you don't have gold annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfb92535",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The Ares 3 mission to Mars is scheduled for 2032. The Starship rocket build by SpaceX will take off from Boca Chica, carrying the astronauts Max Rutherford, Elena Soto, and Jake Martinez.\"\n",
    "gold = [\n",
    "    Launcher(mention=\"Starship\",space_company=\"SpaceX\",crew=[\"Max Rutherford\",\"Elena Soto\",\"Jake Martinez\"]),\n",
    "    Mission(mention=\"Ares 3\",date=\"2032\",departure=\"Boca Chica\",destination=\"Mars\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90501322",
   "metadata": {},
   "source": [
    "## Filling a template\n",
    "\n",
    "We need to define a template. For this task, we will include only the class definitions and the text to be annotated. However, you can design different templates to incorporate more information (for example, event triggers, as demonstrated in the Event Extraction notebook).\n",
    "\n",
    "We will use Jinja templates, which are easy to implement and exceptionally fast. For more information, visit: https://jinja.palletsprojects.com/en/3.1.x/api/#high-level-api.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b365413",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_txt =(\n",
    "\"\"\"# The following lines describe the task definition\n",
    "{%- for definition in guidelines %}\n",
    "{{ definition }}\n",
    "{%- endfor %}\n",
    "\n",
    "# This is the text to analyze\n",
    "text = {{ text.__repr__() }}\n",
    "\n",
    "# The annotation instances that take place in the text above are listed here\n",
    "result = [\n",
    "{%- for ann in annotations %}\n",
    "    {{ ann }},\n",
    "{%- endfor %}\n",
    "]\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f54034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = jinja2Template(template_txt)\n",
    "# Fill the template\n",
    "formated_text = template.render(guidelines=guidelines, text=text, annotations=gold, gold=gold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886dbc0c",
   "metadata": {},
   "source": [
    "### Black Code Formatter\n",
    "\n",
    "We use the Black Code Formatter to automatically unify all the prompts to the same format. \n",
    "\n",
    "https://github.com/psf/black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8994924",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_mode = black.Mode()\n",
    "formated_text = black.format_str(formated_text, mode=black_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80aa5c0e",
   "metadata": {},
   "source": [
    "### Print the filled and formatted template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa5f3106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"># The following lines describe the task definition\n",
       "@dataclass\n",
       "class <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Launcher</span><span style=\"font-weight: bold\">(</span>Template<span style=\"font-weight: bold\">)</span>:\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"Refers to a vehicle designed primarily to transport payloads from the Earth's\n",
       "    surface to space. Launchers can carry various payloads, including satellites,\n",
       "    crewed spacecraft, and cargo, into various orbits or even beyond Earth's orbit.\n",
       "    They are usually multi-stage vehicles that use rocket engines for propulsion.<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "\n",
       "    mention: str\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    The name of the launcher vehicle. \n",
       "    Such as: <span style=\"color: #008000; text-decoration-color: #008000\">\"Sturn V\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Atlas V\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Soyuz\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Ariane 5\"</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    space_company: str  # The company that operates the launcher. Such as: <span style=\"color: #008000; text-decoration-color: #008000\">\"Blue origin\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"ESA\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Boeing\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"ISRO\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Northrop Grumman\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Arianespace\"</span>\n",
       "    crew: List<span style=\"font-weight: bold\">[</span>\n",
       "        str\n",
       "    <span style=\"font-weight: bold\">]</span>  # Names of the crew members boarding the Launcher. Such as: <span style=\"color: #008000; text-decoration-color: #008000\">\"Neil Armstrong\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Michael Collins\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Buzz </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Aldrin\"</span>\n",
       "\n",
       "\n",
       "@dataclass\n",
       "class <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Mission</span><span style=\"font-weight: bold\">(</span>Template<span style=\"font-weight: bold\">)</span>:\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"Any planned or accomplished journey beyond Earth's atmosphere with specific objectives,\n",
       "    either crewed or uncrewed. It includes missions to satellites, the International\n",
       "    Space Station <span style=\"font-weight: bold\">(</span>ISS<span style=\"font-weight: bold\">)</span>, other celestial bodies, and deep space.<span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "\n",
       "    mention: str\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    The name of the mission. \n",
       "    Such as: <span style=\"color: #008000; text-decoration-color: #008000\">\"Apollo 11\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Artemis\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Mercury\"</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">\"\"</span>\"\n",
       "    date: str  # The start date of the mission\n",
       "    departure: str  # The place from which the vehicle will be launched. Such as: <span style=\"color: #008000; text-decoration-color: #008000\">\"Florida\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Houston\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"French </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Guiana\"</span>\n",
       "    destination: str  # The place or planet to which the launcher will be sent. Such as <span style=\"color: #008000; text-decoration-color: #008000\">\"Moon\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"low-orbit\"</span>, \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Saturn\"</span>\n",
       "\n",
       "\n",
       "# This is the text to analyze\n",
       "text = <span style=\"color: #008000; text-decoration-color: #008000\">\"The Ares 3 mission to Mars is scheduled for 2032. The Starship rocket build by SpaceX will take off from </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">Boca Chica, carrying the astronauts Max Rutherford, Elena Soto, and Jake Martinez.\"</span>\n",
       "\n",
       "# The annotation instances that take place in the text above are listed here\n",
       "result = <span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Launcher</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">mention</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Starship\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">space_company</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"SpaceX\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">crew</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Max Rutherford\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Elena Soto\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Jake Martinez\"</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Mission</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">mention</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Ares 3\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">date</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"2032\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">departure</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Boca Chica\"</span>, <span style=\"color: #808000; text-decoration-color: #808000\">destination</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Mars\"</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "# The following lines describe the task definition\n",
       "@dataclass\n",
       "class \u001B[1;35mLauncher\u001B[0m\u001B[1m(\u001B[0mTemplate\u001B[1m)\u001B[0m:\n",
       "    \u001B[32m\"\"\u001B[0m\"Refers to a vehicle designed primarily to transport payloads from the Earth's\n",
       "    surface to space. Launchers can carry various payloads, including satellites,\n",
       "    crewed spacecraft, and cargo, into various orbits or even beyond Earth's orbit.\n",
       "    They are usually multi-stage vehicles that use rocket engines for propulsion.\u001B[32m\"\"\u001B[0m\"\n",
       "\n",
       "    mention: str\n",
       "    \u001B[32m\"\"\u001B[0m\"\n",
       "    The name of the launcher vehicle. \n",
       "    Such as: \u001B[32m\"Sturn V\"\u001B[0m, \u001B[32m\"Atlas V\"\u001B[0m, \u001B[32m\"Soyuz\"\u001B[0m, \u001B[32m\"Ariane 5\"\u001B[0m\n",
       "    \u001B[32m\"\"\u001B[0m\"\n",
       "    space_company: str  # The company that operates the launcher. Such as: \u001B[32m\"Blue origin\"\u001B[0m, \u001B[32m\"ESA\"\u001B[0m, \u001B[32m\"Boeing\"\u001B[0m, \u001B[32m\"ISRO\"\u001B[0m, \n",
       "\u001B[32m\"Northrop Grumman\"\u001B[0m, \u001B[32m\"Arianespace\"\u001B[0m\n",
       "    crew: List\u001B[1m[\u001B[0m\n",
       "        str\n",
       "    \u001B[1m]\u001B[0m  # Names of the crew members boarding the Launcher. Such as: \u001B[32m\"Neil Armstrong\"\u001B[0m, \u001B[32m\"Michael Collins\"\u001B[0m, \u001B[32m\"Buzz \u001B[0m\n",
       "\u001B[32mAldrin\"\u001B[0m\n",
       "\n",
       "\n",
       "@dataclass\n",
       "class \u001B[1;35mMission\u001B[0m\u001B[1m(\u001B[0mTemplate\u001B[1m)\u001B[0m:\n",
       "    \u001B[32m\"\"\u001B[0m\"Any planned or accomplished journey beyond Earth's atmosphere with specific objectives,\n",
       "    either crewed or uncrewed. It includes missions to satellites, the International\n",
       "    Space Station \u001B[1m(\u001B[0mISS\u001B[1m)\u001B[0m, other celestial bodies, and deep space.\u001B[32m\"\"\u001B[0m\"\n",
       "\n",
       "    mention: str\n",
       "    \u001B[32m\"\"\u001B[0m\"\n",
       "    The name of the mission. \n",
       "    Such as: \u001B[32m\"Apollo 11\"\u001B[0m, \u001B[32m\"Artemis\"\u001B[0m, \u001B[32m\"Mercury\"\u001B[0m\n",
       "    \u001B[32m\"\"\u001B[0m\"\n",
       "    date: str  # The start date of the mission\n",
       "    departure: str  # The place from which the vehicle will be launched. Such as: \u001B[32m\"Florida\"\u001B[0m, \u001B[32m\"Houston\"\u001B[0m, \u001B[32m\"French \u001B[0m\n",
       "\u001B[32mGuiana\"\u001B[0m\n",
       "    destination: str  # The place or planet to which the launcher will be sent. Such as \u001B[32m\"Moon\"\u001B[0m, \u001B[32m\"low-orbit\"\u001B[0m, \n",
       "\u001B[32m\"Saturn\"\u001B[0m\n",
       "\n",
       "\n",
       "# This is the text to analyze\n",
       "text = \u001B[32m\"The Ares 3 mission to Mars is scheduled for 2032. The Starship rocket build by SpaceX will take off from \u001B[0m\n",
       "\u001B[32mBoca Chica, carrying the astronauts Max Rutherford, Elena Soto, and Jake Martinez.\"\u001B[0m\n",
       "\n",
       "# The annotation instances that take place in the text above are listed here\n",
       "result = \u001B[1m[\u001B[0m\n",
       "    \u001B[1;35mLauncher\u001B[0m\u001B[1m(\u001B[0m\n",
       "        \u001B[33mmention\u001B[0m=\u001B[32m\"Starship\"\u001B[0m,\n",
       "        \u001B[33mspace_company\u001B[0m=\u001B[32m\"SpaceX\"\u001B[0m,\n",
       "        \u001B[33mcrew\u001B[0m=\u001B[1m[\u001B[0m\u001B[32m\"Max Rutherford\"\u001B[0m, \u001B[32m\"Elena Soto\"\u001B[0m, \u001B[32m\"Jake Martinez\"\u001B[0m\u001B[1m]\u001B[0m,\n",
       "    \u001B[1m)\u001B[0m,\n",
       "    \u001B[1;35mMission\u001B[0m\u001B[1m(\u001B[0m\u001B[33mmention\u001B[0m=\u001B[32m\"Ares\u001B[0m\u001B[32m 3\"\u001B[0m, \u001B[33mdate\u001B[0m=\u001B[32m\"2032\"\u001B[0m, \u001B[33mdeparture\u001B[0m=\u001B[32m\"Boca\u001B[0m\u001B[32m Chica\"\u001B[0m, \u001B[33mdestination\u001B[0m=\u001B[32m\"Mars\"\u001B[0m\u001B[1m)\u001B[0m,\n",
       "\u001B[1m]\u001B[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(formated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6165c0d",
   "metadata": {},
   "source": [
    "## Prepare model inputs\n",
    "\n",
    "We remove everything after `result =` to run inference with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19eabf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt, _ = formated_text.split(\"result =\")\n",
    "prompt = prompt + \"result =\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0620be2",
   "metadata": {},
   "source": [
    "Tokenize the input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f13c79d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input = tokenizer(prompt, add_special_tokens=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff91970",
   "metadata": {},
   "source": [
    "Remove the `eos` token from the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee9d69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input[\"input_ids\"] = model_input[\"input_ids\"][:, :-1]\n",
    "model_input[\"attention_mask\"] = model_input[\"attention_mask\"][:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6718528",
   "metadata": {},
   "source": [
    "## Run Task-Aware MoE LoRA\n",
    "\n",
    "We generate the predictions using the Task-Aware MoE Lora.\n",
    "\n",
    "We use `num_beams=1` and `do_sample=False` in our experiments. Feel free to experiment with different decoding strategies.\n",
    "\n",
    "But, before running, it is important to move the model to the GPU. Otherwise, execution will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f2527fb-3e13-45b6-97b7-21c7a8aa3038",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): MoELoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32016, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): MoELoraLinear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_route): Linear(in_features=4864, out_features=8, bias=False)\n",
       "              )\n",
       "              (k_proj): MoELoraLinear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_route): Linear(in_features=4864, out_features=8, bias=False)\n",
       "              )\n",
       "              (v_proj): MoELoraLinear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_route): Linear(in_features=4864, out_features=8, bias=False)\n",
       "              )\n",
       "              (o_proj): MoELoraLinear(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_route): Linear(in_features=4864, out_features=8, bias=False)\n",
       "              )\n",
       "              (rotary_emb): FlashRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): MoELoraLinear(\n",
       "                in_features=4096, out_features=11008, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_route): Linear(in_features=4864, out_features=8, bias=False)\n",
       "              )\n",
       "              (up_proj): MoELoraLinear(\n",
       "                in_features=4096, out_features=11008, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_route): Linear(in_features=4864, out_features=8, bias=False)\n",
       "              )\n",
       "              (down_proj): MoELoraLinear(\n",
       "                in_features=11008, out_features=4096, bias=False\n",
       "                (lora_dropout): Dropout(p=0.05, inplace=False)\n",
       "                (lora_route): Linear(in_features=11776, out_features=8, bias=False)\n",
       "              )\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32016, bias=False)\n",
       "    )\n",
       "    (task_model): T5Model(\n",
       "      (shared): Embedding(32100, 768)\n",
       "      (encoder): T5Stack(\n",
       "        (embed_tokens): Embedding(32100, 768)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 12)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseActDense(\n",
       "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): ReLU()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-11): 11 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseActDense(\n",
       "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): ReLU()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (decoder): T5Stack(\n",
       "        (embed_tokens): Embedding(32100, 768)\n",
       "        (block): ModuleList(\n",
       "          (0): T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (relative_attention_bias): Embedding(32, 12)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseActDense(\n",
       "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): ReLU()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1-11): 11 x T5Block(\n",
       "            (layer): ModuleList(\n",
       "              (0): T5LayerSelfAttention(\n",
       "                (SelfAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (1): T5LayerCrossAttention(\n",
       "                (EncDecAttention): T5Attention(\n",
       "                  (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                  (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (2): T5LayerFF(\n",
       "                (DenseReluDense): T5DenseActDense(\n",
       "                  (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
       "                  (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                  (act): ReLU()\n",
       "                )\n",
       "                (layer_norm): T5LayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (final_layer_norm): T5LayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f95263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['# The following lines describe the task definition\\n@dataclass\\nclass Launcher(Template):\\n    \"\"\"Refers to a vehicle designed primarily to transport payloads from the Earth\\'s\\n    surface to space. Launchers can carry various payloads, including satellites,\\n    crewed spacecraft, and cargo, into various orbits or even beyond Earth\\'s orbit.\\n    They are usually multi-stage vehicles that use rocket engines for propulsion.\"\"\"\\n\\n    mention: str\\n    \"\"\"\\n    The name of the launcher vehicle. \\n    Such as: \"Sturn V\", \"Atlas V\", \"Soyuz\", \"Ariane 5\"\\n    \"\"\"\\n    space_company: str  # The company that operates the launcher. Such as: \"Blue origin\", \"ESA\", \"Boeing\", \"ISRO\", \"Northrop Grumman\", \"Arianespace\"\\n    crew: List[\\n        str\\n    ]  # Names of the crew members boarding the Launcher. Such as: \"Neil Armstrong\", \"Michael Collins\", \"Buzz Aldrin\"\\n\\n\\n@dataclass\\nclass Mission(Template):\\n    \"\"\"Any planned or accomplished journey beyond Earth\\'s atmosphere with specific objectives,\\n    either crewed or uncrewed. It includes missions to satellites, the International\\n    Space Station (ISS), other celestial bodies, and deep space.\"\"\"\\n\\n    mention: str\\n    \"\"\"\\n    The name of the mission. \\n    Such as: \"Apollo 11\", \"Artemis\", \"Mercury\"\\n    \"\"\"\\n    date: str  # The start date of the mission\\n    departure: str  # The place from which the vehicle will be launched. Such as: \"Florida\", \"Houston\", \"French Guiana\"\\n    destination: str  # The place or planet to which the launcher will be sent. Such as \"Moon\", \"low-orbit\", \"Saturn\"\\n\\n\\n# This is the text to analyze\\ntext = \"The Ares 3 mission to Mars is scheduled for 2032. The Starship rocket build by SpaceX will take off from Boca Chica, carrying the astronauts Max Rutherford, Elena Soto, and Jake Martinez.\"\\n\\n# The annotation instances that take place in the text above are listed here\\nresult =']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.06 s, sys: 180 ms, total: 5.24 s\n",
      "Wall time: 11.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_ouput = model.generate(\n",
    "    **model_input.to(model.device),\n",
    "    max_new_tokens=128,\n",
    "    do_sample=False,\n",
    "    min_new_tokens=0,\n",
    "    num_beams=1,\n",
    "    num_return_sequences=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f4a2a",
   "metadata": {},
   "source": [
    "### Print the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31808b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Mission</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">mention</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Ares 3\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">date</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"2032\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">departure</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Boca Chica\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">destination</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Mars\"</span>,\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Launcher</span><span style=\"font-weight: bold\">(</span>\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">mention</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Starship\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">space_company</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"SpaceX\"</span>,\n",
       "        <span style=\"color: #808000; text-decoration-color: #808000\">crew</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Max Rutherford\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Elena Soto\"</span>, <span style=\"color: #008000; text-decoration-color: #008000\">\"Jake Martinez\"</span><span style=\"font-weight: bold\">]</span>,\n",
       "    <span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"font-weight: bold\">]</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m[\u001B[0m\n",
       "    \u001B[1;35mMission\u001B[0m\u001B[1m(\u001B[0m\n",
       "        \u001B[33mmention\u001B[0m=\u001B[32m\"Ares\u001B[0m\u001B[32m 3\"\u001B[0m,\n",
       "        \u001B[33mdate\u001B[0m=\u001B[32m\"2032\"\u001B[0m,\n",
       "        \u001B[33mdeparture\u001B[0m=\u001B[32m\"Boca\u001B[0m\u001B[32m Chica\"\u001B[0m,\n",
       "        \u001B[33mdestination\u001B[0m=\u001B[32m\"Mars\"\u001B[0m,\n",
       "    \u001B[1m)\u001B[0m,\n",
       "    \u001B[1;35mLauncher\u001B[0m\u001B[1m(\u001B[0m\n",
       "        \u001B[33mmention\u001B[0m=\u001B[32m\"Starship\"\u001B[0m,\n",
       "        \u001B[33mspace_company\u001B[0m=\u001B[32m\"SpaceX\"\u001B[0m,\n",
       "        \u001B[33mcrew\u001B[0m=\u001B[1m[\u001B[0m\u001B[32m\"Max Rutherford\"\u001B[0m, \u001B[32m\"Elena Soto\"\u001B[0m, \u001B[32m\"Jake Martinez\"\u001B[0m\u001B[1m]\u001B[0m,\n",
       "    \u001B[1m)\u001B[0m,\n",
       "\u001B[1m]\u001B[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for y, x in enumerate(model_ouput):\n",
    "    print(f\"Answer {y}\")\n",
    "    rich.print(tokenizer.decode(x,skip_special_tokens=True).split(\"result = \")[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e2013f",
   "metadata": {},
   "source": [
    "## Parse the output\n",
    "\n",
    "The output is a Python list of instances, we can execute it  ðŸ¤¯\n",
    "\n",
    "We define the AnnotationList class to parse the output with a single line of code. The `AnnotationList.from_output` function filters any label that we did not define (hallucinations) to prevent getting an `undefined class` error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2b4aea8-3bbb-49c1-be2a-7361bb122f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tokenizer.decode(x,skip_special_tokens=True).split(\"result = \")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3f6108f-c1d0-4940-a79b-53eb962cb681",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = AnnotationList.from_output(ann, \"guidelines\", text, False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27586bd8",
   "metadata": {},
   "source": [
    "Labels are an instance of the defined classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2703325b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ares 3'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[0].mention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c52537",
   "metadata": {},
   "source": [
    "# Evaluate the result\n",
    "\n",
    "Finally, we will evaluate the outputs from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715535b7",
   "metadata": {},
   "source": [
    "First, we define an Scorer, for Named Entity Recognition, we will use the `SpanScorer` class.\n",
    "\n",
    "We need to define the `valid_types` for the scorer, which will be the labels that we have defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d44e1f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tasks.utils_scorer import TemplateScorer\n",
    "\n",
    "class MyScorer(TemplateScorer):\n",
    "    \"\"\"Compute the F1 score for Generic Task\"\"\"\n",
    "\n",
    "    valid_types: List[Type] = ENTITY_DEFINITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9907289",
   "metadata": {},
   "source": [
    "### Instanciate the scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "93d6c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = MyScorer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb11ce1",
   "metadata": {},
   "source": [
    "### Compute F1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da72e844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'templates'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'f1-score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'class_scores'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Launcher'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'tp'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pos'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pre'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'f1-score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'Mission'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'tp'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pos'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'total_pre'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>,\n",
       "                <span style=\"color: #008000; text-decoration-color: #008000\">'f1-score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>\n",
       "            <span style=\"font-weight: bold\">}</span>\n",
       "        <span style=\"font-weight: bold\">}</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #008000; text-decoration-color: #008000\">'slots'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'precision'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'recall'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'f1-score'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001B[1m{\u001B[0m\n",
       "    \u001B[32m'templates'\u001B[0m: \u001B[1m{\u001B[0m\n",
       "        \u001B[32m'precision'\u001B[0m: \u001B[1;36m1.0\u001B[0m,\n",
       "        \u001B[32m'recall'\u001B[0m: \u001B[1;36m1.0\u001B[0m,\n",
       "        \u001B[32m'f1-score'\u001B[0m: \u001B[1;36m1.0\u001B[0m,\n",
       "        \u001B[32m'class_scores'\u001B[0m: \u001B[1m{\u001B[0m\n",
       "            \u001B[32m'Launcher'\u001B[0m: \u001B[1m{\u001B[0m\n",
       "                \u001B[32m'tp'\u001B[0m: \u001B[1;36m1\u001B[0m,\n",
       "                \u001B[32m'total_pos'\u001B[0m: \u001B[1;36m1\u001B[0m,\n",
       "                \u001B[32m'total_pre'\u001B[0m: \u001B[1;36m1\u001B[0m,\n",
       "                \u001B[32m'precision'\u001B[0m: \u001B[1;36m1.0\u001B[0m,\n",
       "                \u001B[32m'recall'\u001B[0m: \u001B[1;36m1.0\u001B[0m,\n",
       "                \u001B[32m'f1-score'\u001B[0m: \u001B[1;36m1.0\u001B[0m\n",
       "            \u001B[1m}\u001B[0m,\n",
       "            \u001B[32m'Mission'\u001B[0m: \u001B[1m{\u001B[0m\n",
       "                \u001B[32m'tp'\u001B[0m: \u001B[1;36m1\u001B[0m,\n",
       "                \u001B[32m'total_pos'\u001B[0m: \u001B[1;36m1\u001B[0m,\n",
       "                \u001B[32m'total_pre'\u001B[0m: \u001B[1;36m1\u001B[0m,\n",
       "                \u001B[32m'precision'\u001B[0m: \u001B[1;36m1.0\u001B[0m,\n",
       "                \u001B[32m'recall'\u001B[0m: \u001B[1;36m1.0\u001B[0m,\n",
       "                \u001B[32m'f1-score'\u001B[0m: \u001B[1;36m1.0\u001B[0m\n",
       "            \u001B[1m}\u001B[0m\n",
       "        \u001B[1m}\u001B[0m\n",
       "    \u001B[1m}\u001B[0m,\n",
       "    \u001B[32m'slots'\u001B[0m: \u001B[1m{\u001B[0m\u001B[32m'precision'\u001B[0m: \u001B[1;36m1.0\u001B[0m, \u001B[32m'recall'\u001B[0m: \u001B[1;36m1.0\u001B[0m, \u001B[32m'f1-score'\u001B[0m: \u001B[1;36m1.0\u001B[0m\u001B[1m}\u001B[0m\n",
       "\u001B[1m}\u001B[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scorer_results = scorer(reference=[gold],predictions=[result])\n",
    "rich.print(scorer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d86d47e",
   "metadata": {},
   "source": [
    "With this examples, we observe that the Task-Aware MoE LoRA model is capable of correctly identifying the\n",
    "\n",
    "GoLLIE will perform well on labels with well-defined and clearly bounded guidelines. \n",
    "\n",
    "Please share your cool experiments with us; we'd love to see what everyone is doing with GoLLIE!\n",
    "- [@iker_garciaf](https://twitter.com/iker_garciaf)\n",
    "- [@osainz59](https://twitter.com/osainz59)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tamoelora_python]",
   "language": "python",
   "name": "conda-env-tamoelora_python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
